{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ed48d27b-dcd0-4757-89c0-d82098bac11f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/prasad/tf-gpu/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2024-11-06 09:22:50.338018: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-11-06 09:22:50.439272: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-11-06 09:22:50.474771: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-11-06 09:22:50.485802: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-11-06 09:22:50.547005: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-11-06 09:22:51.203436: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer, AdamW, Trainer, TrainingArguments\n",
    "from datasets import load_dataset\n",
    "import os\n",
    "#from torch.optim import AdamW\n",
    "import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c6e4ea0-83e5-4bbb-b71f-0120f3a559a7",
   "metadata": {},
   "source": [
    "## Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e4284883-6c70-4f7f-ac6c-e4ef33781502",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['content'],\n",
       "        num_rows: 6286\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = load_dataset(\"text\", data_files=os.path.join('../utils/investopedia-dictionary', \"*.txt\"))\n",
    "dataset = dataset.rename_column(\"text\", \"content\")\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d93aa612-c3cc-447c-9210-80295bcbf13a",
   "metadata": {},
   "source": [
    "## Initialize tokenizer and model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "53d089af-ba8d-49fc-90f6-6249d57a496c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "model = GPT2LMHeadModel.from_pretrained('gpt2')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76e891cd-0650-4ef0-b4a5-50212787f399",
   "metadata": {},
   "source": [
    "## Tokenize and encode the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "7e0b771e-9122-47f6-9e10-fb13be214d26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['content', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 6286\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def tokenize_function(example):\n",
    "    return tokenizer(example[\"content\"], truncation=True, max_length=512, padding=\"max_length\")\n",
    "\n",
    "tokenized_dataset = dataset.map(tokenize_function, batched=True)\n",
    "tokenized_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "54e3ca63-b925-4757-bf2b-9a7d09008ea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    input_ids = [item[\"input_ids\"] for item in batch]\n",
    "    attention_masks = [item[\"attention_mask\"] for item in batch]\n",
    "    labels = [item[\"input_ids\"] for item in batch]\n",
    "\n",
    "    # Convert lists to tensors\n",
    "    input_ids = torch.tensor(input_ids)\n",
    "    attention_masks = torch.tensor(attention_masks)\n",
    "    labels = torch.tensor(labels)\n",
    "\n",
    "    # Pad sequences to the same length\n",
    "    input_ids = torch.nn.utils.rnn.pad_sequence(input_ids, batch_first=True)\n",
    "    attention_masks = torch.nn.utils.rnn.pad_sequence(attention_masks, batch_first=True)\n",
    "    labels = torch.nn.utils.rnn.pad_sequence(labels, batch_first=True)\n",
    "\n",
    "    return {\n",
    "        \"input_ids\": input_ids,\n",
    "        \"attention_mask\": attention_masks,\n",
    "        \"labels\": labels,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "1df517af-fede-490e-9b66-d1cec29c96ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the data for training\n",
    "train_dataset = tokenized_dataset[\"train\"]\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=3, shuffle=True,collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "9928ab3d-ba2a-4bb9-9a24-a9083cf4f3bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the training parameters\n",
    "#device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device = torch.device(\"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "optimizer = AdamW(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "c0894d7d-9f0b-4c32-b62b-a35e7dd16a2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Step: 0, Loss: 3.0407874584198\n",
      "Epoch: 1, Step: 0, Loss: 3.1183090209960938\n",
      "Epoch: 2, Step: 0, Loss: 3.2722361087799072\n",
      "Epoch: 3, Step: 0, Loss: 3.196629762649536\n",
      "Epoch: 4, Step: 0, Loss: 3.5147719383239746\n",
      "Epoch: 5, Step: 0, Loss: 3.4762418270111084\n",
      "Epoch: 6, Step: 0, Loss: 3.268984794616699\n",
      "Epoch: 7, Step: 0, Loss: 3.1798107624053955\n",
      "Epoch: 8, Step: 0, Loss: 3.357325315475464\n",
      "Epoch: 9, Step: 0, Loss: 3.0354466438293457\n",
      "Epoch: 10, Step: 0, Loss: 3.30102276802063\n",
      "Epoch: 11, Step: 0, Loss: 3.3638834953308105\n",
      "Epoch: 12, Step: 0, Loss: 3.047879695892334\n",
      "Epoch: 13, Step: 0, Loss: 3.171254873275757\n",
      "Epoch: 14, Step: 0, Loss: 3.4327175617218018\n",
      "Epoch: 15, Step: 0, Loss: 3.2706329822540283\n",
      "Epoch: 16, Step: 0, Loss: 3.4898040294647217\n",
      "Epoch: 17, Step: 0, Loss: 3.0628507137298584\n",
      "Epoch: 18, Step: 0, Loss: 3.1088216304779053\n",
      "Epoch: 19, Step: 0, Loss: 3.1916584968566895\n",
      "Epoch: 20, Step: 0, Loss: 3.4200263023376465\n",
      "Epoch: 21, Step: 0, Loss: 3.486119270324707\n",
      "Epoch: 22, Step: 0, Loss: 3.448028564453125\n",
      "Epoch: 23, Step: 0, Loss: 3.323192596435547\n",
      "Epoch: 24, Step: 0, Loss: 3.16361665725708\n",
      "Epoch: 25, Step: 0, Loss: 3.4047887325286865\n",
      "Epoch: 26, Step: 0, Loss: 2.9009509086608887\n",
      "Epoch: 27, Step: 0, Loss: 3.0850234031677246\n",
      "Epoch: 28, Step: 0, Loss: 3.1106622219085693\n",
      "Epoch: 29, Step: 0, Loss: 3.231398582458496\n",
      "Epoch: 30, Step: 0, Loss: 2.905782699584961\n",
      "Epoch: 31, Step: 0, Loss: 3.245480537414551\n",
      "Epoch: 32, Step: 0, Loss: 3.277771234512329\n",
      "Epoch: 33, Step: 0, Loss: 3.6151108741760254\n",
      "Epoch: 34, Step: 0, Loss: 3.152412176132202\n",
      "Epoch: 35, Step: 0, Loss: 2.9340596199035645\n",
      "Epoch: 36, Step: 0, Loss: 3.2290029525756836\n",
      "Epoch: 37, Step: 0, Loss: 3.197096586227417\n",
      "Epoch: 38, Step: 0, Loss: 3.2863757610321045\n",
      "Epoch: 39, Step: 0, Loss: 3.394979953765869\n",
      "Epoch: 40, Step: 0, Loss: 3.276195764541626\n",
      "Epoch: 41, Step: 0, Loss: 3.0647311210632324\n",
      "Epoch: 42, Step: 0, Loss: 3.5909173488616943\n",
      "Epoch: 43, Step: 0, Loss: 3.0382792949676514\n",
      "Epoch: 44, Step: 0, Loss: 3.317932367324829\n",
      "Epoch: 45, Step: 0, Loss: 3.3747684955596924\n",
      "Epoch: 46, Step: 0, Loss: 3.325305223464966\n",
      "Epoch: 47, Step: 0, Loss: 3.1101040840148926\n",
      "Epoch: 48, Step: 0, Loss: 3.121925115585327\n",
      "Epoch: 49, Step: 0, Loss: 3.1312615871429443\n",
      "Epoch: 50, Step: 0, Loss: 3.0620014667510986\n",
      "Epoch: 51, Step: 0, Loss: 3.3729453086853027\n",
      "Epoch: 52, Step: 0, Loss: 3.2497875690460205\n",
      "Epoch: 53, Step: 0, Loss: 3.0594801902770996\n",
      "Epoch: 54, Step: 0, Loss: 3.3252108097076416\n",
      "Epoch: 55, Step: 0, Loss: 3.225688934326172\n",
      "Epoch: 56, Step: 0, Loss: 3.6817474365234375\n",
      "Epoch: 57, Step: 0, Loss: 3.1018385887145996\n",
      "Epoch: 58, Step: 0, Loss: 3.0018413066864014\n",
      "Epoch: 59, Step: 0, Loss: 3.2713518142700195\n",
      "Epoch: 60, Step: 0, Loss: 3.0107555389404297\n",
      "Epoch: 61, Step: 0, Loss: 3.119629144668579\n",
      "Epoch: 62, Step: 0, Loss: 3.234196662902832\n",
      "Epoch: 63, Step: 0, Loss: 3.0082616806030273\n",
      "Epoch: 64, Step: 0, Loss: 3.243055820465088\n",
      "Epoch: 65, Step: 0, Loss: 3.255079984664917\n",
      "Epoch: 66, Step: 0, Loss: 3.236846446990967\n",
      "Epoch: 67, Step: 0, Loss: 3.439624071121216\n",
      "Epoch: 68, Step: 0, Loss: 3.3745791912078857\n",
      "Epoch: 69, Step: 0, Loss: 3.112964391708374\n",
      "Epoch: 70, Step: 0, Loss: 3.0491180419921875\n",
      "Epoch: 71, Step: 0, Loss: 3.1189465522766113\n",
      "Epoch: 72, Step: 0, Loss: 3.4478695392608643\n",
      "Epoch: 73, Step: 0, Loss: 3.1460683345794678\n",
      "Epoch: 74, Step: 0, Loss: 3.094320774078369\n",
      "Epoch: 75, Step: 0, Loss: 3.157184600830078\n",
      "Epoch: 76, Step: 0, Loss: 3.1125426292419434\n",
      "Epoch: 77, Step: 0, Loss: 3.2681031227111816\n",
      "Epoch: 78, Step: 0, Loss: 3.066469669342041\n",
      "Epoch: 79, Step: 0, Loss: 3.2147140502929688\n",
      "Epoch: 80, Step: 0, Loss: 3.3122096061706543\n",
      "Epoch: 81, Step: 0, Loss: 3.3488502502441406\n",
      "Epoch: 82, Step: 0, Loss: 3.409381866455078\n",
      "Epoch: 83, Step: 0, Loss: 3.6009743213653564\n",
      "Epoch: 84, Step: 0, Loss: 3.1572086811065674\n",
      "Epoch: 85, Step: 0, Loss: 2.880200147628784\n",
      "Epoch: 86, Step: 0, Loss: 2.9671413898468018\n",
      "Epoch: 87, Step: 0, Loss: 3.185985803604126\n",
      "Epoch: 88, Step: 0, Loss: 3.2811696529388428\n",
      "Epoch: 89, Step: 0, Loss: 3.2822580337524414\n",
      "Epoch: 90, Step: 0, Loss: 2.9767415523529053\n",
      "Epoch: 91, Step: 0, Loss: 3.1208431720733643\n",
      "Epoch: 92, Step: 0, Loss: 3.3325233459472656\n",
      "Epoch: 93, Step: 0, Loss: 3.1779749393463135\n",
      "Epoch: 94, Step: 0, Loss: 3.1763412952423096\n",
      "Epoch: 95, Step: 0, Loss: 3.0918452739715576\n",
      "Epoch: 96, Step: 0, Loss: 3.1749017238616943\n",
      "Epoch: 97, Step: 0, Loss: 3.4008948802948\n",
      "Epoch: 98, Step: 0, Loss: 3.253509998321533\n",
      "Epoch: 99, Step: 0, Loss: 3.2949132919311523\n"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "model.train()\n",
    "num_epochs=100\n",
    "for epoch in range(num_epochs):\n",
    "    for step,batch in enumerate(train_dataloader):\n",
    "        input_ids = batch[\"input_ids\"].to(device)\n",
    "        attention_mask = batch[\"attention_mask\"].to(device)\n",
    "        labels = batch[\"input_ids\"].to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
    "        loss = outputs.loss\n",
    "        if step%400==0:\n",
    "            print(\"Epoch: {}, Step: {}, Loss: {}\".format(epoch, step, loss.item()))\n",
    "            break\n",
    "        loss.backward()\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4934596-f1e9-45d6-953f-af80cdab406e",
   "metadata": {},
   "source": [
    "## Test Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "845fb7ea-0604-4fc4-8d49-f7a9badf863e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What is IPO?\n",
      "\n",
      "The \"Pursuit of IPO\" scheme is one in which the investor is paid to acquire a share for a value of their money or for a share to-be-acquired financial service service (i.e. a share of a company) (I.D). The investor may obtain from the company a share of a share of their net income or income to be transferred to other persons.\n",
      "\n",
      "The \"Pursuit of IPO\" is one of the two forms of the \"Pursuit of IPO\" scheme. A, to-be-acquired financial service service service with a net-inflation share of $1 (or their own net-inflation share) is provided to an investor for the investor by the investors' initial investment and all subsequent shares of that financial service service are transferred to the investor's net-inflation share or to their share of the assets (i.e. a share of a company in a class); a, b or c, d, e, f, g, h, i, j, k, l, m, n, o, o, p, q, r, s, tr, t, u, v, z, or z,\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prompt = \"What is IPO?\"\n",
    "\n",
    "input_ids = tokenizer(prompt, return_tensors=\"pt\").input_ids\n",
    "#input_ids = input_ids.to(device)\n",
    "\n",
    "model = model.to('cpu')  # Move the model to GPU\n",
    "gen_tokens = model.generate(\n",
    "    input_ids,\n",
    "    do_sample=True,\n",
    "    temperature=0.9,\n",
    "    max_length=256,\n",
    ")\n",
    "print(tokenizer.batch_decode(gen_tokens)[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7d82f95-556c-4b35-877e-6a87945ffcab",
   "metadata": {},
   "source": [
    "## Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "03ec8ab4-9bf2-4901-b027-167187ca9325",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('./models/first_model/tokenizer_config.json',\n",
       " './models/first_model/special_tokens_map.json',\n",
       " './models/first_model/vocab.json',\n",
       " './models/first_model/merges.txt',\n",
       " './models/first_model/added_tokens.json')"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.save_pretrained(\"./models/first_model\")\n",
    "tokenizer.save_pretrained(\"./models/first_model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4461485b-3b05-4673-9728-627b22f29fbc",
   "metadata": {},
   "source": [
    "## Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "cf2e8587-5c84-4378-b588-5960ee06df3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "gc.collect()\n",
    "print(torch.cuda.is_available())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
